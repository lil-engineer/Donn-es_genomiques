{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genetic ID</th>\n",
       "      <th>Master ID</th>\n",
       "      <th>Skeletal code</th>\n",
       "      <th>Skeletal element</th>\n",
       "      <th>Year data from this individual was first published [for a present-day individuals we give the data of the data reported here; missing GreenScience 2010 (Vi33.15, Vi33.26), Olalde2018 (I2657), RasmussenNature2010 (Australian)]</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Method for Determining Date; unless otherwise specified, calibrations use 95.4% intervals from OxCal v4.4.2 Bronk Ramsey (2009); r5; Atmospheric data from Reimer et al (2020)</th>\n",
       "      <th>Date mean in BP in years before 1950 CE [OxCal mu for a direct radiocarbon date, and average of range for a contextual date]</th>\n",
       "      <th>Date standard deviation in BP [OxCal sigma for a direct radiocarbon date, and standard deviation of the uniform distribution between the two bounds for a contextual date]</th>\n",
       "      <th>Full Date One of two formats. (Format 1) 95.4% CI calibrated radiocarbon age (Conventional Radiocarbon Age BP, Lab number) e.g. 2624-2350 calBCE (3990±40 BP, Ua-35016). (Format 2) Archaeological context range, e.g. 2500-1700 BCE</th>\n",
       "      <th>...</th>\n",
       "      <th>Y haplogroup (manual curation in ISOGG format)</th>\n",
       "      <th>mtDNA coverage (merged data)</th>\n",
       "      <th>mtDNA haplogroup if &gt;2x or published</th>\n",
       "      <th>mtDNA match to consensus if &gt;2x (merged data)</th>\n",
       "      <th>Damage rate in first nucleotide on sequences overlapping 1240k targets (merged data)</th>\n",
       "      <th>Sex ratio [Y/(Y+X) counts] (merged data)</th>\n",
       "      <th>Library type (minus=no.damage.correction, half=damage.retained.at.last.position, plus=damage.fully.corrected, ds=double.stranded.library.preparation, ss=single.stranded.library.preparation)</th>\n",
       "      <th>Libraries</th>\n",
       "      <th>ASSESSMENT</th>\n",
       "      <th>ASSESSMENT WARNINGS (Xcontam interval is listed if lower bound is &gt;0.005, \"QUESTIONABLE\" if lower bound is 0.01-0.02, \"QUESTIONABLE_CRITICAL\" or \"FAIL\" if lower bound is &gt;0.02) (mtcontam confidence interval is listed if coverage &gt;2 and upper bound is &lt;0.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I001.HO</td>\n",
       "      <td>I001</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>2016</td>\n",
       "      <td>BroushakiScience2016</td>\n",
       "      <td>Modern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>PASS</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I002.HO</td>\n",
       "      <td>I002</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>2016</td>\n",
       "      <td>BroushakiScience2016</td>\n",
       "      <td>Modern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>PASS</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IREJ-T006.HO</td>\n",
       "      <td>IREJ-T006</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>2016</td>\n",
       "      <td>BroushakiScience2016</td>\n",
       "      <td>Modern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>PASS</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IREJ-T009.HO</td>\n",
       "      <td>IREJ-T009</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>2016</td>\n",
       "      <td>BroushakiScience2016</td>\n",
       "      <td>Modern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>PASS</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IREJ-T022.HO</td>\n",
       "      <td>IREJ-T022</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>2016</td>\n",
       "      <td>BroushakiScience2016</td>\n",
       "      <td>Modern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>PASS</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Genetic ID  Master ID Skeletal code Skeletal element  \\\n",
       "0       I001.HO       I001            ..               ..   \n",
       "1       I002.HO       I002            ..               ..   \n",
       "2  IREJ-T006.HO  IREJ-T006            ..               ..   \n",
       "3  IREJ-T009.HO  IREJ-T009            ..               ..   \n",
       "4  IREJ-T022.HO  IREJ-T022            ..               ..   \n",
       "\n",
       "  Year data from this individual was first published [for a present-day individuals we give the data of the data reported here; missing GreenScience 2010 (Vi33.15, Vi33.26), Olalde2018 (I2657), RasmussenNature2010 (Australian)]  \\\n",
       "0                                               2016                                                                                                                                                                                  \n",
       "1                                               2016                                                                                                                                                                                  \n",
       "2                                               2016                                                                                                                                                                                  \n",
       "3                                               2016                                                                                                                                                                                  \n",
       "4                                               2016                                                                                                                                                                                  \n",
       "\n",
       "            Publication  \\\n",
       "0  BroushakiScience2016   \n",
       "1  BroushakiScience2016   \n",
       "2  BroushakiScience2016   \n",
       "3  BroushakiScience2016   \n",
       "4  BroushakiScience2016   \n",
       "\n",
       "  Method for Determining Date; unless otherwise specified, calibrations use 95.4% intervals from OxCal v4.4.2 Bronk Ramsey (2009); r5; Atmospheric data from Reimer et al (2020)  \\\n",
       "0                                             Modern                                                                                                                               \n",
       "1                                             Modern                                                                                                                               \n",
       "2                                             Modern                                                                                                                               \n",
       "3                                             Modern                                                                                                                               \n",
       "4                                             Modern                                                                                                                               \n",
       "\n",
       "   Date mean in BP in years before 1950 CE [OxCal mu for a direct radiocarbon date, and average of range for a contextual date]  \\\n",
       "0                                                  0                                                                              \n",
       "1                                                  0                                                                              \n",
       "2                                                  0                                                                              \n",
       "3                                                  0                                                                              \n",
       "4                                                  0                                                                              \n",
       "\n",
       "   Date standard deviation in BP [OxCal sigma for a direct radiocarbon date, and standard deviation of the uniform distribution between the two bounds for a contextual date]  \\\n",
       "0                                                  0                                                                                                                            \n",
       "1                                                  0                                                                                                                            \n",
       "2                                                  0                                                                                                                            \n",
       "3                                                  0                                                                                                                            \n",
       "4                                                  0                                                                                                                            \n",
       "\n",
       "  Full Date One of two formats. (Format 1) 95.4% CI calibrated radiocarbon age (Conventional Radiocarbon Age BP, Lab number) e.g. 2624-2350 calBCE (3990±40 BP, Ua-35016). (Format 2) Archaeological context range, e.g. 2500-1700 BCE  \\\n",
       "0                                            present                                                                                                                                                                                     \n",
       "1                                            present                                                                                                                                                                                     \n",
       "2                                            present                                                                                                                                                                                     \n",
       "3                                            present                                                                                                                                                                                     \n",
       "4                                            present                                                                                                                                                                                     \n",
       "\n",
       "   ... Y haplogroup (manual curation in ISOGG format)  \\\n",
       "0  ...                                             ..   \n",
       "1  ...                                             ..   \n",
       "2  ...                                             ..   \n",
       "3  ...                                             ..   \n",
       "4  ...                                             ..   \n",
       "\n",
       "  mtDNA coverage (merged data) mtDNA haplogroup if >2x or published  \\\n",
       "0                           ..                                   ..   \n",
       "1                           ..                                   ..   \n",
       "2                           ..                                   ..   \n",
       "3                           ..                                   ..   \n",
       "4                           ..                                   ..   \n",
       "\n",
       "  mtDNA match to consensus if >2x (merged data)  \\\n",
       "0                                            ..   \n",
       "1                                            ..   \n",
       "2                                            ..   \n",
       "3                                            ..   \n",
       "4                                            ..   \n",
       "\n",
       "  Damage rate in first nucleotide on sequences overlapping 1240k targets (merged data)  \\\n",
       "0                                                 ..                                     \n",
       "1                                                 ..                                     \n",
       "2                                                 ..                                     \n",
       "3                                                 ..                                     \n",
       "4                                                 ..                                     \n",
       "\n",
       "  Sex ratio [Y/(Y+X) counts] (merged data)  \\\n",
       "0                                       ..   \n",
       "1                                       ..   \n",
       "2                                       ..   \n",
       "3                                       ..   \n",
       "4                                       ..   \n",
       "\n",
       "  Library type (minus=no.damage.correction, half=damage.retained.at.last.position, plus=damage.fully.corrected, ds=double.stranded.library.preparation, ss=single.stranded.library.preparation)  \\\n",
       "0                                                 ..                                                                                                                                              \n",
       "1                                                 ..                                                                                                                                              \n",
       "2                                                 ..                                                                                                                                              \n",
       "3                                                 ..                                                                                                                                              \n",
       "4                                                 ..                                                                                                                                              \n",
       "\n",
       "  Libraries ASSESSMENT  \\\n",
       "0        ..       PASS   \n",
       "1        ..       PASS   \n",
       "2        ..       PASS   \n",
       "3        ..       PASS   \n",
       "4        ..       PASS   \n",
       "\n",
       "  ASSESSMENT WARNINGS (Xcontam interval is listed if lower bound is >0.005, \"QUESTIONABLE\" if lower bound is 0.01-0.02, \"QUESTIONABLE_CRITICAL\" or \"FAIL\" if lower bound is >0.02) (mtcontam confidence interval is listed if coverage >2 and upper bound is <0.  \n",
       "0                                                 ..                                                                                                                                                                                                              \n",
       "1                                                 ..                                                                                                                                                                                                              \n",
       "2                                                 ..                                                                                                                                                                                                              \n",
       "3                                                 ..                                                                                                                                                                                                              \n",
       "4                                                 ..                                                                                                                                                                                                              \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_public_HO = pd.read_csv(r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Analysis\\v54.1.p1_HO_public.csv',low_memory=False)\n",
    "df_public_HO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>GeneticDistance(cM)</th>\n",
       "      <th>BasePair_Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rs3094315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>752566 G A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs7419119</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022518</td>\n",
       "      <td>842013 T G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs13302957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024116</td>\n",
       "      <td>891021 G A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs6696609</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>903426 C T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs8997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025727</td>\n",
       "      <td>949654 A G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SNP  Chromosome  GeneticDistance(cM) BasePair_Position\n",
       "0   rs3094315           1             0.020130        752566 G A\n",
       "1   rs7419119           1             0.022518        842013 T G\n",
       "2  rs13302957           1             0.024116        891021 G A\n",
       "3   rs6696609           1             0.024457        903426 C T\n",
       "4      rs8997           1             0.025727        949654 A G"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_public_HO2=pd.read_csv(r'v54.1.p1_HO_public (2).csv',low_memory=False)\n",
    "df_public_HO2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is example of how we will be loading geno data to manage memory constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from genetics import loadRawGenoFile, unpackfullgenofile, unpackAndFilterSNPs\n",
    "# we are processing the rows of geno file in chunks to manage our RAM Storage \n",
    "def process_with_memmap_in_chunks(filename, chunk_size=10000):\n",
    "    geno_file, nind, nsnp, rlen = loadRawGenoFile(filename)\n",
    "    geno = np.memmap(filename, dtype='uint8', mode='r', shape=(nsnp, rlen))\n",
    "    for start in range(0, nsnp, chunk_size):\n",
    "        end = min(start + chunk_size, nsnp)\n",
    "        chunk = geno[start:end]\n",
    "        chunk_unpacked = np.unpackbits(chunk, axis=1)[:, :(2 * nind)]\n",
    "        # Process or save the chunk as needed\n",
    "        # Example: Print the shape of the unpacked chunk\n",
    "        print(f\"Processed chunk {start} to {end} with shape {chunk_unpacked.shape}\")\n",
    "\n",
    "# Example usage\n",
    "process_with_memmap_in_chunks(r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Files\\v54.1.p1_HO_public.geno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chunk 0 to 10000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 1 1 1 1 1 1 1 1 1] ...\n",
      "Processed chunk 10000 to 20000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 0 0 0 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 0 1 1 0 0 1] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 1 1 0 1 0 0 1 0 1] ...\n",
      "Sample 5: [1 0 1 0 0 0 1 0 1 0] ...\n",
      "Processed chunk 20000 to 30000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 2: [0 0 0 0 0 1 1 0 0 0] ...\n",
      "Sample 3: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 30000 to 40000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 0 1 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 1 0 1 0 1 1 0 1 0] ...\n",
      "Processed chunk 40000 to 50000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 1 0 1 0 0 1 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 0 0 1 1 0 0 0 0 1] ...\n",
      "Sample 5: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Processed chunk 50000 to 60000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 1 1 0 0 1 1 0] ...\n",
      "Sample 2: [0 1 0 0 0 0 0 1 0 0] ...\n",
      "Sample 3: [0 1 0 1 0 0 0 1 0 0] ...\n",
      "Sample 4: [0 1 0 1 0 0 0 0 0 1] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 60000 to 70000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 1 1 0 0 0 1 0] ...\n",
      "Sample 2: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 3: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 4: [0 1 1 0 1 0 1 0 0 1] ...\n",
      "Sample 5: [1 0 0 1 1 0 1 0 1 0] ...\n",
      "Processed chunk 70000 to 80000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [0 1 0 0 0 1 1 0 0 1] ...\n",
      "Sample 3: [1 0 1 0 1 0 0 0 0 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Processed chunk 80000 to 90000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 0 1 1 0 0 0 0 1] ...\n",
      "Sample 2: [1 0 1 0 1 0 0 1 1 0] ...\n",
      "Sample 3: [0 1 0 1 0 1 1 0 1 0] ...\n",
      "Sample 4: [0 1 1 0 1 0 1 0 0 1] ...\n",
      "Sample 5: [0 0 0 1 0 1 0 1 0 0] ...\n",
      "Processed chunk 90000 to 100000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 0 1 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 5: [1 0 0 1 0 1 0 1 0 1] ...\n",
      "Processed chunk 100000 to 110000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 0 0 0 1 1 0 0 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 1 0 1 0 1 0 0 0 1] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 110000 to 120000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 1 1 0 1 0 0 1 1 0] ...\n",
      "Sample 4: [0 1 0 0 0 0 0 0 0 0] ...\n",
      "Sample 5: [1 0 0 1 1 0 1 0 1 0] ...\n",
      "Processed chunk 120000 to 130000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 1 1 0 0 1 1 0] ...\n",
      "Sample 2: [1 0 1 0 0 1 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 0 1 0 1] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 1 0 1 0 1 0 1 0 1] ...\n",
      "Processed chunk 130000 to 140000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 1 0 0 0 0 0 0] ...\n",
      "Sample 2: [1 0 1 0 0 1 1 0 1 0] ...\n",
      "Sample 3: [0 0 0 0 0 0 0 1 0 1] ...\n",
      "Sample 4: [0 1 0 0 1 0 0 1 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 140000 to 150000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 0 1 1 0] ...\n",
      "Sample 3: [0 1 0 0 0 0 0 0 0 0] ...\n",
      "Sample 4: [0 0 1 0 0 1 0 1 0 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 150000 to 160000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 0 0 1 0 0 1] ...\n",
      "Sample 2: [1 0 0 1 0 0 0 1 0 1] ...\n",
      "Sample 3: [0 1 1 0 0 1 0 1 0 0] ...\n",
      "Sample 4: [1 1 1 1 1 1 1 1 1 1] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 160000 to 170000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 0 0 1 1 0 1 0] ...\n",
      "Sample 2: [1 0 0 0 0 0 0 1 0 0] ...\n",
      "Sample 3: [0 1 1 0 1 0 0 1 0 0] ...\n",
      "Sample 4: [0 1 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 1 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 170000 to 180000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 1 0 1 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 0 0 1 0 0 0 0 0 1] ...\n",
      "Sample 4: [0 0 0 0 0 0 0 0 0 1] ...\n",
      "Sample 5: [1 0 1 0 0 0 0 0 0 0] ...\n",
      "Processed chunk 180000 to 190000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 0 0 1 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 0 1] ...\n",
      "Processed chunk 190000 to 200000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 1 1 0 0 1 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 1 0 1 1 0 0 1 0 1] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 0 1] ...\n",
      "Processed chunk 200000 to 210000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 0 1 0 1 0 0] ...\n",
      "Sample 2: [0 1 1 0 1 0 1 0 0 1] ...\n",
      "Sample 3: [1 0 1 0 0 1 1 0 0 1] ...\n",
      "Sample 4: [1 0 1 0 1 0 0 0 0 1] ...\n",
      "Sample 5: [1 0 0 1 1 0 0 1 1 0] ...\n",
      "Processed chunk 210000 to 220000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 0 1 0 0 0 0 1 0] ...\n",
      "Sample 3: [0 1 0 1 0 0 0 0 0 0] ...\n",
      "Sample 4: [1 0 0 1 0 1 0 1 1 0] ...\n",
      "Sample 5: [0 1 0 1 1 1 0 1 0 0] ...\n",
      "Processed chunk 220000 to 230000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 1 0 1 0 1 1 0] ...\n",
      "Sample 2: [0 1 0 0 0 1 0 0 0 1] ...\n",
      "Sample 3: [0 0 0 1 0 0 0 0 0 1] ...\n",
      "Sample 4: [0 1 0 1 0 0 0 1 0 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 230000 to 240000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 0 0 1 0 0 1 0] ...\n",
      "Sample 2: [0 1 1 0 0 1 1 0 0 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 0 1 1 0 1 0 1 0] ...\n",
      "Processed chunk 240000 to 250000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 0 0 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 1 0 1 1 0 0 1 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Processed chunk 250000 to 260000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 0 1 0 1 0 1 1 0] ...\n",
      "Sample 3: [1 0 0 1 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 1 0 1 0 1 0 1 0 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 260000 to 270000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 1 0 1 0 0 0 0 1] ...\n",
      "Sample 2: [1 0 1 0 0 1 0 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 0 0 0 1 0 0 0 0 1] ...\n",
      "Processed chunk 270000 to 280000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 0 0 1 0 0 0 0] ...\n",
      "Sample 2: [1 0 1 0 0 1 1 0 0 1] ...\n",
      "Sample 3: [1 0 0 1 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 0 0 1 0 0 0 0 0 0] ...\n",
      "Sample 5: [1 0 1 0 0 1 0 1 1 0] ...\n",
      "Processed chunk 280000 to 290000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 0 1 0 0 0 1] ...\n",
      "Processed chunk 290000 to 300000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 1 1 1 1 1 1 1 1 1] ...\n",
      "Sample 3: [0 1 1 0 1 0 0 1 0 1] ...\n",
      "Sample 4: [1 0 1 0 0 1 1 0 1 0] ...\n",
      "Sample 5: [1 0 0 0 0 1 1 0 1 0] ...\n",
      "Processed chunk 300000 to 310000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 1 0 0 1 1 0 0 1] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 1 0 0 0 1 1 0 0 1] ...\n",
      "Sample 4: [0 1 0 0 1 0 0 1 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 0 1] ...\n",
      "Processed chunk 310000 to 320000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 1 0 0 0 0 0 0 1] ...\n",
      "Sample 2: [1 0 1 1 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 0 1 0 1 0 1 0 0] ...\n",
      "Sample 5: [0 1 0 1 1 0 0 1 1 0] ...\n",
      "Processed chunk 320000 to 330000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 0 0 0 0 1 0 0 0 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 330000 to 340000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 1 0 1 0 0 1 1 0] ...\n",
      "Sample 2: [1 1 1 1 1 1 1 1 1 1] ...\n",
      "Sample 3: [0 1 0 1 0 1 1 0 0 1] ...\n",
      "Sample 4: [0 1 1 0 0 1 0 0 0 1] ...\n",
      "Sample 5: [1 0 1 0 0 1 1 0 0 1] ...\n",
      "Processed chunk 340000 to 350000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 1 0 1 0 0 1 0 1] ...\n",
      "Sample 2: [1 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 3: [0 0 0 0 0 1 0 0 0 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 350000 to 360000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 0 1 1 0] ...\n",
      "Sample 2: [1 1 1 1 1 1 1 1 1 1] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 0 1 1 0 0 1 0 1] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 360000 to 370000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 1 1 0 0 1 0 0 0 0] ...\n",
      "Sample 4: [1 0 1 0 0 1 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 370000 to 380000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 0 0 1 0 0 0 0 1] ...\n",
      "Sample 2: [0 1 1 0 0 1 0 1 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 0 0 1 1 0 0 1 0 1] ...\n",
      "Processed chunk 380000 to 390000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [0 1 0 0 0 1 0 1 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 390000 to 400000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 1 0 1 0 0 0 0] ...\n",
      "Sample 2: [0 0 0 0 0 1 0 0 0 1] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 0 0 0 0 0 0 1 0 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 0 1 1 0] ...\n",
      "Processed chunk 400000 to 410000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 1 0 1 1 0 1 0] ...\n",
      "Sample 2: [1 0 0 0 1 0 0 1 0 1] ...\n",
      "Sample 3: [0 1 0 0 0 1 0 0 0 1] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 410000 to 420000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [0 0 0 1 0 0 0 0 0 0] ...\n",
      "Sample 3: [0 1 0 1 0 1 1 0 0 0] ...\n",
      "Sample 4: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 5: [1 0 0 1 1 0 0 1 1 0] ...\n",
      "Processed chunk 420000 to 430000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [0 1 1 0 0 1 1 0 0 1] ...\n",
      "Sample 3: [1 0 1 0 0 1 1 0 0 1] ...\n",
      "Sample 4: [1 0 0 1 0 1 0 1 0 1] ...\n",
      "Sample 5: [0 1 1 0 0 1 1 0 1 0] ...\n",
      "Processed chunk 430000 to 440000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 440000 to 450000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [0 0 0 0 0 0 0 1 0 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 0 1 0 1 0 1 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 0 1] ...\n",
      "Processed chunk 450000 to 460000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 0 1 1 0] ...\n",
      "Sample 2: [0 0 1 0 0 0 0 1 0 0] ...\n",
      "Sample 3: [1 0 0 1 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 0 0 1 0 0 0 0 0 0] ...\n",
      "Sample 5: [0 1 1 0 0 1 1 0 0 1] ...\n",
      "Processed chunk 460000 to 470000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 0 1 0 1 1 0] ...\n",
      "Processed chunk 470000 to 480000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 1 0 1 0 1 1 0] ...\n",
      "Sample 2: [0 1 1 0 0 1 0 1 0 1] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 480000 to 490000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 0 0 0 0 1 0 0 0 0] ...\n",
      "Sample 4: [1 0 1 0 0 0 1 0 1 0] ...\n",
      "Sample 5: [0 0 0 0 0 0 0 0 0 0] ...\n",
      "Processed chunk 490000 to 500000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 1 0 0 1 0 1 0 1] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 1 0 1 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 0 1 0 0 1 0 1 0 1] ...\n",
      "Processed chunk 500000 to 510000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 1 1 0 1 0 0 1] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 0 1 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 0 1] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 510000 to 520000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 1 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 1 0 1 0 1 1 0 0 1] ...\n",
      "Processed chunk 520000 to 530000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 0 0 0 1 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 1 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 0 1 0 1 0 1 0 0 1] ...\n",
      "Processed chunk 530000 to 540000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 0 0 0 0 0 1 0] ...\n",
      "Sample 2: [0 1 0 0 1 0 0 1 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 1 1 0 1 0 0 1 1 0] ...\n",
      "Sample 5: [1 0 1 0 0 1 1 0 0 1] ...\n",
      "Processed chunk 540000 to 550000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 0 0 0 0 0 1 0 0] ...\n",
      "Sample 2: [1 0 0 1 0 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 0 1 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 0 1] ...\n",
      "Sample 5: [0 1 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 550000 to 560000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 0 0 1 0 0 0 0 0 1] ...\n",
      "Sample 5: [0 1 0 0 0 1 0 1 0 0] ...\n",
      "Processed chunk 560000 to 570000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 0 1 1 0 1 0 0 1] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [0 1 1 1 0 1 1 0 1 0] ...\n",
      "Sample 4: [0 1 1 0 1 0 0 1 0 1] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Processed chunk 570000 to 580000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 1 0 1 0 1 0 1 1 0] ...\n",
      "Sample 2: [0 1 0 1 0 1 1 0 0 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 1 0 1 1 0 0 1 0 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 0 1 1 0] ...\n",
      "Processed chunk 580000 to 590000 with shape (10000, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [0 0 1 0 0 0 1 0 0 1] ...\n",
      "Sample 2: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 5: [0 0 0 0 0 1 1 0 0 0] ...\n",
      "Processed chunk 590000 to 597573 with shape (7573, 41006)\n",
      "Sample of unpacked data:\n",
      "Sample 1: [1 0 1 0 1 0 1 0 0 1] ...\n",
      "Sample 2: [0 0 0 1 0 0 0 0 1 1] ...\n",
      "Sample 3: [1 0 1 0 1 0 1 0 1 0] ...\n",
      "Sample 4: [0 0 1 0 0 0 1 0 0 0] ...\n",
      "Sample 5: [1 0 1 0 1 0 1 0 1 0] ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from genetics import loadRawGenoFile, unpackfullgenofile, unpackAndFilterSNPs\n",
    "\n",
    "def process_with_memmap_in_chunks(filename, chunk_size=10000, sample_size=5):\n",
    "    # Load metadata and initialize memory-mapped file\n",
    "    geno_file, nind, nsnp, rlen = loadRawGenoFile(filename)\n",
    "    geno = np.memmap(filename, dtype='uint8', mode='r', shape=(nsnp, rlen))\n",
    "    \n",
    "    # Process data in chunks\n",
    "    for start in range(0, nsnp, chunk_size):\n",
    "        end = min(start + chunk_size, nsnp)\n",
    "        chunk = geno[start:end]\n",
    "        chunk_unpacked = np.unpackbits(chunk, axis=1)[:, :(2 * nind)]\n",
    "        \n",
    "        # Print sample data from the chunk\n",
    "        print(f\"Processed chunk {start} to {end} with shape {chunk_unpacked.shape}\")\n",
    "        \n",
    "        # Display a sample of the unpacked data\n",
    "        sample_indices = np.random.choice(chunk_unpacked.shape[0], size=min(sample_size, chunk_unpacked.shape[0]), replace=False)\n",
    "        sample_data = chunk_unpacked[sample_indices]\n",
    "        \n",
    "        print(\"Sample of unpacked data:\")\n",
    "        for i, row in enumerate(sample_data):\n",
    "            print(f\"Sample {i + 1}: {row[:10]} ...\")  # Print only the first 10 elements for brevity\n",
    "\n",
    "# Example usage\n",
    "process_with_memmap_in_chunks(r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Files\\v54.1.p1_HO_public.geno')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering for Y chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_chromosome_snps = df_public_HO2[df_public_HO2['Chromosome'] == 24].copy()\n",
    "\n",
    "# Extract SNP IDs for filtering the .geno file later\n",
    "y_snp_ids = y_chromosome_snps['SNP'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>GeneticDistance(cM)</th>\n",
       "      <th>BasePair_Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596976</th>\n",
       "      <td>rs11575897</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2655180 G A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596977</th>\n",
       "      <td>rs2253109</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2661694 A G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596978</th>\n",
       "      <td>rs2058276</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2668456 T C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596979</th>\n",
       "      <td>rs113328317</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2668533 C A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596980</th>\n",
       "      <td>rs34402762</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2710309 T G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SNP  Chromosome  GeneticDistance(cM) BasePair_Position\n",
       "596976   rs11575897          24                  0.0       2655180 G A\n",
       "596977    rs2253109          24                  0.0       2661694 A G\n",
       "596978    rs2058276          24                  0.0       2668456 T C\n",
       "596979  rs113328317          24                  0.0       2668533 C A\n",
       "596980   rs34402762          24                  0.0       2710309 T G"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_chromosome_snps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_y_chromosome_geno(geno_filename, y_snp_ids, chunk_size=10000):\n",
    "    geno_file, nind, nsnp, rlen = loadRawGenoFile(geno_filename)\n",
    "    geno = np.memmap(geno_filename, dtype='uint8', mode='r', shape=(nsnp, rlen))\n",
    "    filtered_data = []\n",
    "    \n",
    "    for start in range(0, nsnp, chunk_size):\n",
    "        end = min(start + chunk_size, nsnp)\n",
    "        chunk = geno[start:end]\n",
    "        chunk_unpacked = np.unpackbits(chunk, axis=1)[:, :(2 * nind)]\n",
    "        \n",
    "        # Filter the chunk for Y chromosome SNPs\n",
    "        chunk_filtered = chunk_unpacked[np.isin(range(start, end), y_snp_ids)]\n",
    "        filtered_data.append(chunk_filtered)\n",
    "        \n",
    "    return np.vstack(filtered_data)\n",
    "\n",
    "# Example usage\n",
    "y_chromosome_geno_data = filter_y_chromosome_geno(r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Files\\v54.1.p1_HO_public.geno', y_snp_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk from 0 to 10000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 10000 to 20000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 20000 to 30000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 30000 to 40000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 40000 to 50000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 50000 to 60000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 60000 to 70000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 70000 to 80000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 80000 to 90000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 90000 to 100000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 100000 to 110000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 110000 to 120000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 120000 to 130000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 130000 to 140000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 140000 to 150000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 150000 to 160000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 160000 to 170000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 170000 to 180000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 180000 to 190000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 190000 to 200000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 200000 to 210000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 210000 to 220000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 220000 to 230000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 230000 to 240000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 240000 to 250000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 250000 to 260000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 260000 to 270000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 270000 to 280000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 280000 to 290000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 290000 to 300000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 300000 to 310000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 310000 to 320000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 320000 to 330000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 330000 to 340000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 340000 to 350000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 350000 to 360000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 360000 to 370000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 370000 to 380000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 380000 to 390000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 390000 to 400000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 400000 to 410000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 410000 to 420000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 420000 to 430000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 430000 to 440000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 440000 to 450000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 450000 to 460000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 460000 to 470000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 470000 to 480000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 480000 to 490000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 490000 to 500000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 500000 to 510000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 510000 to 520000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 520000 to 530000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 530000 to 540000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 540000 to 550000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 550000 to 560000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 560000 to 570000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 570000 to 580000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 580000 to 590000, shape: (10000, 5126)\n",
      "Unpacked chunk shape: (10000, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Processing chunk from 590000 to 597573, shape: (7573, 5126)\n",
      "Unpacked chunk shape: (7573, 41006)\n",
      "Y SNP indices for current chunk: [False False False ... False False False]\n",
      "Filtered chunk shape: (0, 41006)\n",
      "Y chromosome genotype data shape: (0, 41006)\n"
     ]
    }
   ],
   "source": [
    "def filter_y_chromosome_geno(geno_filename, y_snp_ids, chunk_size=10000):\n",
    "    geno_file, nind, nsnp, rlen = loadRawGenoFile(geno_filename)\n",
    "    geno = np.memmap(geno_filename, dtype='uint8', mode='r', shape=(nsnp, rlen))\n",
    "    filtered_data = []\n",
    "    \n",
    "    for start in range(0, nsnp, chunk_size):\n",
    "        end = min(start + chunk_size, nsnp)\n",
    "        chunk = geno[start:end]\n",
    "        print(f'Processing chunk from {start} to {end}, shape: {chunk.shape}')\n",
    "        chunk_unpacked = np.unpackbits(chunk, axis=1)[:, :(2 * nind)]\n",
    "        print(f'Unpacked chunk shape: {chunk_unpacked.shape}')\n",
    "        \n",
    "        # Filter the chunk for Y chromosome SNPs\n",
    "        y_snp_indices = np.isin(range(start, end), y_snp_ids)\n",
    "        print(f'Y SNP indices for current chunk: {y_snp_indices}')\n",
    "        \n",
    "        chunk_filtered = chunk_unpacked[y_snp_indices]\n",
    "        print(f'Filtered chunk shape: {chunk_filtered.shape}')\n",
    "        \n",
    "        filtered_data.append(chunk_filtered)\n",
    "        \n",
    "    return np.vstack(filtered_data) if filtered_data else np.array([])\n",
    "\n",
    "# Example usage\n",
    "y_chromosome_geno_data = filter_y_chromosome_geno(r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Files\\v54.1.p1_HO_public.geno', y_snp_ids)\n",
    "print(f'Y chromosome genotype data shape: {y_chromosome_geno_data.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 41006), dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_chromosome_geno_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map SNP IDs to Indices:\n",
    "\n",
    "#### Our .geno file uses SNP IDs or positions, we need to map these to the indices used in the .geno file. This will allow us to select the appropriate rows from the .geno file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Y chromosome data shape: (597, 41006)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_snp_table(snp_table_filename):\n",
    "    # Load the SNP table (assumed to be in CSV format for this example)\n",
    "    snp_table = pd.read_csv(snp_table_filename)\n",
    "    return snp_table\n",
    "\n",
    "def filter_y_chromosome_snps(geno_filename, snp_table_filename, chunk_size=10000):\n",
    "    # Load the SNP information table\n",
    "    snp_table = load_snp_table(snp_table_filename)\n",
    "    \n",
    "    # Filter for Y chromosome SNPs (assuming a column 'chromosome' and 'snp_id')\n",
    "    y_chromosome_snps = snp_table[snp_table['Chromosome'] == 24]['SNP']\n",
    "    \n",
    "    # Convert SNP IDs to indices (assuming you have a mapping function)\n",
    "    snp_id_to_index = {snp_id: idx for idx, snp_id in enumerate(snp_table['SNP'])}\n",
    "    y_snp_indices = [snp_id_to_index[snp_id] for snp_id in y_chromosome_snps if snp_id in snp_id_to_index]\n",
    "    \n",
    "    # Process the geno file in chunks and filter Y chromosome SNPs\n",
    "    geno_file, nind, nsnp, rlen = loadRawGenoFile(geno_filename)\n",
    "    geno = np.memmap(geno_filename, dtype='uint8', mode='r', shape=(nsnp, rlen))\n",
    "    \n",
    "    filtered_data = []\n",
    "    \n",
    "    for start in range(0, nsnp, chunk_size):\n",
    "        end = min(start + chunk_size, nsnp)\n",
    "        chunk = geno[start:end]\n",
    "        chunk_unpacked = np.unpackbits(chunk, axis=1)[:, :(2 * nind)]\n",
    "        \n",
    "        # Find indices of Y chromosome SNPs in the current chunk\n",
    "        chunk_indices = np.array([idx for idx in y_snp_indices if start <= idx < end])\n",
    "        if chunk_indices.size > 0:\n",
    "            chunk_filtered = chunk_unpacked[chunk_indices - start]\n",
    "            filtered_data.append(chunk_filtered)\n",
    "    \n",
    "    return np.vstack(filtered_data) if filtered_data else np.array([])\n",
    "\n",
    "# Example usage\n",
    "filtered_y_chromosome_data = filter_y_chromosome_snps(\n",
    "    r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Files\\v54.1.p1_HO_public.geno',\n",
    "    r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Analysis\\v54.1.p1_HO_public (2).csv'\n",
    ")\n",
    "print(f'Filtered Y chromosome data shape: {filtered_y_chromosome_data.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 1, 1, 1],\n",
       "       [1, 0, 1, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_y_chromosome_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freelance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
