{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Y chromosome data shape: (597, 41006)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from genetics import loadRawGenoFile, unpackfullgenofile, unpackAndFilterSNPs\n",
    "def load_snp_table(snp_table_filename):\n",
    "    # Load the SNP table (assumed to be in CSV format for this example)\n",
    "    snp_table = pd.read_csv(snp_table_filename)\n",
    "    return snp_table\n",
    "\n",
    "def filter_y_chromosome_snps(geno_filename, snp_table_filename, chunk_size=10000):\n",
    "    # Load the SNP information table\n",
    "    snp_table = load_snp_table(snp_table_filename)\n",
    "    \n",
    "    # Filter for Y chromosome SNPs (assuming a column 'chromosome' and 'snp_id')\n",
    "    y_chromosome_snps = snp_table[snp_table['Chromosome'] == 24]['SNP']\n",
    "    \n",
    "    # Convert SNP IDs to indices (assuming you have a mapping function)\n",
    "    snp_id_to_index = {snp_id: idx for idx, snp_id in enumerate(snp_table['SNP'])}\n",
    "    y_snp_indices = [snp_id_to_index[snp_id] for snp_id in y_chromosome_snps if snp_id in snp_id_to_index]\n",
    "    \n",
    "    # Process the geno file in chunks and filter Y chromosome SNPs\n",
    "    geno_file, nind, nsnp, rlen = loadRawGenoFile(geno_filename)\n",
    "    geno = np.memmap(geno_filename, dtype='uint8', mode='r', shape=(nsnp, rlen))\n",
    "    \n",
    "    filtered_data = []\n",
    "    \n",
    "    for start in range(0, nsnp, chunk_size):\n",
    "        end = min(start + chunk_size, nsnp)\n",
    "        chunk = geno[start:end]\n",
    "        chunk_unpacked = np.unpackbits(chunk, axis=1)[:, :(2 * nind)]\n",
    "        \n",
    "        # Find indices of Y chromosome SNPs in the current chunk\n",
    "        chunk_indices = np.array([idx for idx in y_snp_indices if start <= idx < end])\n",
    "        if chunk_indices.size > 0:\n",
    "            chunk_filtered = chunk_unpacked[chunk_indices - start]\n",
    "            filtered_data.append(chunk_filtered)\n",
    "    \n",
    "    return np.vstack(filtered_data) if filtered_data else np.array([])\n",
    "\n",
    "# Example usage\n",
    "filtered_y_chromosome_data = filter_y_chromosome_snps(\n",
    "    r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Files\\v54.1.p1_HO_public.geno',\n",
    "    r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Analysis\\v54.1.p1_HO_public (2).csv'\n",
    ")\n",
    "print(f'Filtered Y chromosome data shape: {filtered_y_chromosome_data.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_ind_file(ind_filename):\n",
    "    ind_data = pd.read_csv(ind_filename,low_memory=False)  # Adjust based on the actual format\n",
    "    return ind_data\n",
    "\n",
    "# Example usage\n",
    "ind_file = r'C:\\Users\\91735\\OneDrive\\Desktop\\freelance excel\\Fiverr\\Sachaat\\Analysis\\v54.1.p1_HO_public.csv'\n",
    "ind_data = load_ind_file(ind_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Genetic ID', 'Master ID', 'Skeletal code', 'Skeletal element',\n",
       "       'Year data from this individual was first published [for a present-day individuals we give the data of the data reported here; missing GreenScience 2010 (Vi33.15, Vi33.26), Olalde2018 (I2657), RasmussenNature2010 (Australian)]',\n",
       "       'Publication',\n",
       "       'Method for Determining Date; unless otherwise specified, calibrations use 95.4% intervals from OxCal v4.4.2 Bronk Ramsey (2009); r5; Atmospheric data from Reimer et al (2020)',\n",
       "       'Date mean in BP in years before 1950 CE [OxCal mu for a direct radiocarbon date, and average of range for a contextual date]',\n",
       "       'Date standard deviation in BP [OxCal sigma for a direct radiocarbon date, and standard deviation of the uniform distribution between the two bounds for a contextual date]',\n",
       "       'Full Date One of two formats. (Format 1) 95.4% CI calibrated radiocarbon age (Conventional Radiocarbon Age BP, Lab number) e.g. 2624-2350 calBCE (3990Â±40 BP, Ua-35016). (Format 2) Archaeological context range, e.g. 2500-1700 BCE',\n",
       "       'Age at Death from physical anthropology', 'Group ID', 'Locality',\n",
       "       'Political Entity', 'Lat.', 'Long.', 'Pulldown Strategy', 'Data source',\n",
       "       'No. Libraries',\n",
       "       '1240k coverage (taken from original pulldown where possible)',\n",
       "       'SNPs hit on autosomal targets (Computed using easystats on 1240k snpset)',\n",
       "       'SNPs hit on autosomal targets (Computed using easystats on HO snpset)',\n",
       "       'Molecular Sex', 'Family ID and position within family',\n",
       "       'Y haplogroup (manual curation in terminal mutation format)',\n",
       "       'Y haplogroup (manual curation in ISOGG format)',\n",
       "       'mtDNA coverage (merged data)', 'mtDNA haplogroup if >2x or published',\n",
       "       'mtDNA match to consensus if >2x (merged data)',\n",
       "       'Damage rate in first nucleotide on sequences overlapping 1240k targets (merged data)',\n",
       "       'Sex ratio [Y/(Y+X) counts] (merged data)',\n",
       "       'Library type (minus=no.damage.correction, half=damage.retained.at.last.position, plus=damage.fully.corrected, ds=double.stranded.library.preparation, ss=single.stranded.library.preparation)',\n",
       "       'Libraries', 'ASSESSMENT',\n",
       "       'ASSESSMENT WARNINGS (Xcontam interval is listed if lower bound is >0.005, \"QUESTIONABLE\" if lower bound is 0.01-0.02, \"QUESTIONABLE_CRITICAL\" or \"FAIL\" if lower bound is >0.02) (mtcontam confidence interval is listed if coverage >2 and upper bound is <0.'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Genetic ID  \\\n",
      "0       I001.HO   \n",
      "1       I002.HO   \n",
      "2  IREJ-T006.HO   \n",
      "3  IREJ-T009.HO   \n",
      "4  IREJ-T022.HO   \n",
      "\n",
      "  SNPs hit on autosomal targets (Computed using easystats on 1240k snpset)  \n",
      "0                                                 ..                        \n",
      "1                                                 ..                        \n",
      "2                                                 ..                        \n",
      "3                                                 ..                        \n",
      "4                                                 ..                        \n"
     ]
    }
   ],
   "source": [
    "def create_filtered_ind_df(ind_data):\n",
    "    # Select only the relevant columns\n",
    "    relevant_columns = ['Genetic ID', 'SNPs hit on autosomal targets (Computed using easystats on 1240k snpset)']\n",
    "    filtered_ind_data = ind_data[relevant_columns]\n",
    "    return filtered_ind_data\n",
    "\n",
    "# Create a new DataFrame with only the relevant columns\n",
    "filtered_ind_data = create_filtered_ind_df(ind_data)\n",
    "print(filtered_ind_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91735\\AppData\\Local\\Temp\\ipykernel_26904\\591544426.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_ind_data.replace('..',np.nan,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "filtered_ind_data.replace('..',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genetic ID</th>\n",
       "      <th>SNPs hit on autosomal targets (Computed using easystats on 1240k snpset)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I001.HO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I002.HO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IREJ-T006.HO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IREJ-T009.HO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IREJ-T022.HO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Genetic ID  \\\n",
       "0       I001.HO   \n",
       "1       I002.HO   \n",
       "2  IREJ-T006.HO   \n",
       "3  IREJ-T009.HO   \n",
       "4  IREJ-T022.HO   \n",
       "\n",
       "  SNPs hit on autosomal targets (Computed using easystats on 1240k snpset)  \n",
       "0                                                NaN                        \n",
       "1                                                NaN                        \n",
       "2                                                NaN                        \n",
       "3                                                NaN                        \n",
       "4                                                NaN                        "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ind_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered genotype data shape: (597, 16381)\n",
      "Filtered individual data shape: (16381, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def filter_individuals_based_on_missing_data(geno_data, ind_data, missing_threshold=0.4):\n",
    "    # Convert 'SNPs hit on autosomal targets' to numeric, setting errors='coerce' will replace invalid parsing with NaN\n",
    "    ind_data['SNPs hit on autosomal targets (Computed using easystats on 1240k snpset)'] = pd.to_numeric(\n",
    "        ind_data['SNPs hit on autosomal targets (Computed using easystats on 1240k snpset)'], errors='coerce')\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    ind_ids = ind_data['Genetic ID'].values\n",
    "    snps_hit = ind_data['SNPs hit on autosomal targets (Computed using easystats on 1240k snpset)'].values\n",
    "    \n",
    "    # Count the total number of SNPs available\n",
    "    total_snps = geno_data.shape[0]\n",
    "    \n",
    "    # Calculate the proportion of missing SNPs for each individual\n",
    "    missing_data = 1 - (snps_hit / total_snps)\n",
    "    \n",
    "    # Filter out individuals with more than 40% missing data\n",
    "    valid_individuals_mask = missing_data <= missing_threshold\n",
    "    \n",
    "    # Filter ind_data based on valid individuals\n",
    "    filtered_ind_data = ind_data[valid_individuals_mask]\n",
    "    valid_individual_ids = filtered_ind_data['Genetic ID'].values\n",
    "    \n",
    "    # Create a dictionary for fast lookup\n",
    "    id_to_index = {id: idx for idx, id in enumerate(ind_ids)}\n",
    "    \n",
    "    # Create a boolean mask for geno_data columns\n",
    "    geno_indices = [id_to_index[id] for id in valid_individual_ids if id in id_to_index]\n",
    "    valid_individuals_mask = np.zeros(geno_data.shape[1], dtype=bool)\n",
    "    valid_individuals_mask[geno_indices] = True\n",
    "    \n",
    "    # Filter geno_data based on valid individuals\n",
    "    filtered_geno_data = geno_data[:, valid_individuals_mask]\n",
    "    \n",
    "    return filtered_geno_data, filtered_ind_data\n",
    "\n",
    "# Example usage\n",
    "filtered_geno_data, filtered_ind_data = filter_individuals_based_on_missing_data(filtered_y_chromosome_data, filtered_ind_data)\n",
    "print(f'Filtered genotype data shape: {filtered_geno_data.shape}')\n",
    "print(f'Filtered individual data shape: {filtered_ind_data.shape}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freelance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
